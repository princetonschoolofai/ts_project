{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Stock Prediction</h1>\n",
    "<p>The goal here is to find an algorithm that will capture buying, sell and hold signals. There are xxx steps taken:</p>\n",
    "<ol>\n",
    "    <li>Get ETF with the following information: \"open\", \"high\", \"low\", \"close\", \"volume\"</li>\n",
    "    <br>\n",
    "    <li>Calculate all the following information:\n",
    "        <br><b>Volume</b>\n",
    "        <br>\n",
    "        <br>Accumulation/Distribution Index (ADI)\n",
    "        <br>On-Balance Volume (OBV)\n",
    "        <br>Chaikin Money Flow (CMF)\n",
    "        <br>Force Index (FI)\n",
    "        <br>Ease of Movement (EoM, EMV)\n",
    "        <br>Volume-price Trend (VPT)\n",
    "        <br>Negative Volume Index (NVI)\n",
    "        <br>\n",
    "        <br>\n",
    "        <br><b>Volatility</b>\n",
    "        <br>\n",
    "        <br>Average True Range (ATR)\n",
    "        <br>Bollinger Bands (BB)\n",
    "        <br>Keltner Channel (KC)\n",
    "        <br>Donchian Channel (DC)\n",
    "        <br>\n",
    "        <br><b>Trend</b>\n",
    "        <br>\n",
    "        <br>Moving Average Convergence Divergence (MACD)\n",
    "        <br>Average Directional Movement Index (ADX)\n",
    "        <br>Vortex Indicator (VI)\n",
    "        <br>Trix (TRIX)\n",
    "        <br>Mass Index (MI)\n",
    "        <br>Commodity Channel Index (CCI)\n",
    "        <br>Detrended Price Oscillator (DPO)\n",
    "        <br>KST Oscillator (KST)\n",
    "        <br>Ichimoku Kinkō Hyō (Ichimoku)\n",
    "        <br>\n",
    "        <br><b>Momentum</b>\n",
    "        <br>\n",
    "        <br>Money Flow Index (MFI)\n",
    "        <br>Relative Strength Index (RSI)\n",
    "        <br>True strength index (TSI)\n",
    "        <br>Ultimate Oscillator (UO)\n",
    "        <br>Stochastic Oscillator (SR)\n",
    "        <br>Williams %R (WR)\n",
    "        <br>Awesome Oscillator (AO)\n",
    "        <br>\n",
    "        <br><b>Others</b>\n",
    "        <br>\n",
    "        <br>Daily Return (DR)\n",
    "        <br>Daily Log Return (DLR)\n",
    "        <br>Cumulative Return (CR)</li>\n",
    "        <br>\n",
    "        <br>\n",
    "    <li>We normalize each column using normal normalization</li>\n",
    "    <br>\n",
    "    <li> We perform a PCA in each one of the Drivers (OriginalData, Volume,Volatility, Trend, Momentum and Others) and get the number of columns needed to explain, at least 85% in each one of the Drivers (This percentage can be changed, it is a hyperparameter).  </li>\n",
    "    <br>\n",
    "    <li>Make the Following Predictions:</li>\n",
    "        <ul>\n",
    "            <li>Next day up over 0.3%, lower than -0.3% or between</li>\n",
    "        </ul>\n",
    "\n",
    "    \n",
    "\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              open    high     low   close  adjusted_close    volume  \\\n",
      "timestamp                                                              \n",
      "2019-06-27  186.47  186.94  185.99  186.72          186.72  15889915   \n",
      "2019-06-26  186.13  187.33  185.49  185.79          185.79  22512628   \n",
      "2019-06-25  188.06  188.14  184.65  184.93          184.93  33921112   \n",
      "\n",
      "            dividend_amount  split_coefficient  \n",
      "timestamp                                       \n",
      "2019-06-27              0.0                1.0  \n",
      "2019-06-26              0.0                1.0  \n",
      "2019-06-25              0.0                1.0  \n",
      "##########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinic\\Anaconda3\\lib\\site-packages\\ta\\trend.py:170: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  dip[i] = 100 * (dip_mio[i]/trs[i])\n",
      "C:\\Users\\vinic\\Anaconda3\\lib\\site-packages\\ta\\trend.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (dip_mio[i]/trs[i])\n",
      "C:\\Users\\vinic\\Anaconda3\\lib\\site-packages\\ta\\trend.py:174: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  din[i] = 100 * (din_mio[i]/trs[i])\n",
      "C:\\Users\\vinic\\Anaconda3\\lib\\site-packages\\ta\\trend.py:174: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (din_mio[i]/trs[i])\n",
      "C:\\Users\\vinic\\Anaconda3\\lib\\site-packages\\ta\\trend.py:176: RuntimeWarning: invalid value encountered in subtract\n",
      "  dx = 100 * np.abs((dip - din) / (dip + din))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5109, 25)\n",
      "Index(['OriginalData_0', 'OriginalData_1', 'Volume_0', 'Volume_1', 'Volume_2',\n",
      "       'Volume_3', 'Volume_4', 'Volume_5', 'Volatility_0', 'Volatility_1',\n",
      "       'Volatility_2', 'Volatility_3', 'Volatility_4', 'Trend_0', 'Trend_1',\n",
      "       'Trend_2', 'Trend_3', 'Trend_4', 'Trend_5', 'Trend_6', 'Momentum_0',\n",
      "       'Momentum_1', 'Momentum_2', 'Others_0', 'Others_1'],\n",
      "      dtype='object')\n",
      "            OriginalData_0  OriginalData_1  Volume_0  Volume_1  Volume_2  \\\n",
      "timestamp                                                                  \n",
      "2019-06-27        0.041568       -0.008132  0.049774  0.003139 -0.003051   \n",
      "2019-06-26        0.041063       -0.008043  0.077261 -0.004463  0.004619   \n",
      "2019-06-25        0.040478       -0.007935  0.024791 -0.003373  0.000905   \n",
      "2019-06-24        0.081197        0.226276  0.026368 -0.004845  0.006705   \n",
      "2019-06-21        0.041027       -0.008018  0.024165 -0.007306  0.011767   \n",
      "\n",
      "            Volume_3  Volume_4  Volume_5  Volatility_0  Volatility_1  ...  \\\n",
      "timestamp                                                             ...   \n",
      "2019-06-27 -0.113279 -0.038141  0.006760      0.048533      0.006771  ...   \n",
      "2019-06-26 -0.079791 -0.047967 -0.029002      0.048437      0.006764  ...   \n",
      "2019-06-25  0.022646  0.005036 -0.033151      0.048492      0.006842  ...   \n",
      "2019-06-24  0.022235  0.003197 -0.036057      0.048966      0.006975  ...   \n",
      "2019-06-21  0.019742  0.001881 -0.036835      0.049076      0.006972  ...   \n",
      "\n",
      "             Trend_2   Trend_3   Trend_4   Trend_5   Trend_6  Momentum_0  \\\n",
      "timestamp                                                                  \n",
      "2019-06-27  0.220043  0.559576  0.230936  0.706116  0.047715    0.054689   \n",
      "2019-06-26  0.103991  0.165291  0.040818 -0.145019 -0.037486    0.040337   \n",
      "2019-06-25  0.102931  0.165257  0.039253 -0.144448 -0.038598    0.037552   \n",
      "2019-06-24  0.106671  0.161668  0.051355 -0.146122 -0.024183    0.051398   \n",
      "2019-06-21  0.107594  0.162758  0.049368 -0.145935 -0.028146    0.052276   \n",
      "\n",
      "            Momentum_1  Momentum_2  Others_0  Others_1  \n",
      "timestamp                                               \n",
      "2019-06-27    0.058386   -0.029482  0.479816  0.479493  \n",
      "2019-06-26    0.073166   -0.009655 -0.003991  0.001300  \n",
      "2019-06-25    0.075468   -0.006051 -0.003706  0.001234  \n",
      "2019-06-24    0.059573   -0.026029  0.014084 -0.002504  \n",
      "2019-06-21    0.058871   -0.026911  0.001803  0.000071  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "#!pip install ta\n",
    "import ta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from TransformData import Normalizer, PCA_, GetTA\n",
    "\n",
    "\n",
    "\n",
    "pipe = Pipeline([('etf_ta',GetTA()),('normalizing',Normalizer()),('pca',PCA_(0.9))])\n",
    "\n",
    "qqq = pd.read_csv('AlphaVantageDaily_adjusted_qqq.csv', infer_datetime_format=True,  index_col=['timestamp'])\n",
    "print(qqq.head(3))\n",
    "print('##########')\n",
    "\n",
    "qqq_t = pipe.fit_transform(qqq)\n",
    "\n",
    "print(qqq_t.shape)\n",
    "\n",
    "print(qqq_t.columns)\n",
    "\n",
    "print(qqq_t.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predictions</h1>\n",
    "<br>\n",
    "<p>Let's make the first prediction, if the etf is going to go up over 0.3%, below 0.3% or maintain betweet one week from now </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-27\n",
      "1999-03-10\n",
      "2019-06-27\n",
      "1999-03-10\n"
     ]
    }
   ],
   "source": [
    "print(qqq.index[0])\n",
    "print(qqq.index[-1])\n",
    "print(qqq_t.index[0])\n",
    "print(qqq_t.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20720259205744562\n",
      "-0.24596608509596452\n"
     ]
    }
   ],
   "source": [
    "# Creating the Y vector.\n",
    "\n",
    "num = qqq.iloc[0:-5]['adjusted_close']\n",
    "den = qqq.iloc[5:]['adjusted_close']\n",
    "\n",
    "\n",
    "Y = [ x/y - 1 for x,y in zip(num,den)]\n",
    "print(max(Y))\n",
    "print(min(Y))\n",
    "\n",
    "for i in range(len(Y)):\n",
    "    if Y[i] > 0.03:\n",
    "        Y[i] = 0\n",
    "    \n",
    "    elif Y[i] < -0.03:\n",
    "        Y[i] = 2\n",
    "        \n",
    "    else:\n",
    "        Y[i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-27\n",
      "2019-06-20\n",
      "(5104, 25)\n",
      "5104\n"
     ]
    }
   ],
   "source": [
    "# Adjusting the X data to have the same length as Y. The dates also should have one week difference.\n",
    "print(qqq.index[0])\n",
    "X = qqq_t.iloc[5:]\n",
    "print(X.index[0])\n",
    "\n",
    "print(X.shape)\n",
    "print(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 3593, 0: 788, 2: 723}\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "5104\n",
      "(5054, 50, 25)\n",
      "(5054, 1)\n"
     ]
    }
   ],
   "source": [
    "lookback= 50\n",
    "def create_dataset(df,lookback):\n",
    "    finalDf = []\n",
    "    print(lookback)\n",
    "    print(df.shape[0])\n",
    "    for i in range(lookback, df.shape[0]):\n",
    "\n",
    "        finalDf.append(np.array(df.iloc[i-lookback:i]))\n",
    "    finalDf = np.array(finalDf)\n",
    "    return finalDf\n",
    "\n",
    "X = X.reset_index(drop = True)\n",
    "\n",
    "X = create_dataset(X, lookback)\n",
    "Y = Y[:-50]\n",
    "\n",
    "Y = np.array(Y).reshape(len(Y),1)\n",
    "\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 3562, 0: 787, 2: 705}\n"
     ]
    }
   ],
   "source": [
    "# Dealing with unbalanced data\n",
    "\n",
    "def count_(list_):\n",
    "    dict_ = {}\n",
    "    for i in range(len(list_)):\n",
    "        \n",
    "        if list_[i] in dict_.keys():\n",
    "            dict_[list_[i]] = dict_[list_[i]] + 1\n",
    "            \n",
    "        else:\n",
    "            dict_[list_[i]] = 1\n",
    "    return dict_\n",
    "\n",
    "print(count_(Y.reshape(-1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n",
      "505\n",
      "4549\n",
      "(5054, 50, 25)\n",
      "(5054, 50, 25)\n",
      "(2, 50, 25)\n"
     ]
    }
   ],
   "source": [
    "# # Setting a Validation Data aside. This will be done because We'll duplicate the low frequency data. \n",
    "# validation_size = int(0.1*len(Y))\n",
    "\n",
    "# # selecting indexes for validation\n",
    "# indexes = np.random.choice(len(Y), validation_size, replace = False)\n",
    "# y_validation = []\n",
    "# y = []\n",
    "\n",
    "# for i in range(len(Y)):\n",
    "#     if i in indexes:\n",
    "#         y_validation.append(Y[i])\n",
    "        \n",
    "#     else:\n",
    "#         y.append(Y[i])\n",
    "        \n",
    "# print(len(indexes))\n",
    "# print(len(y_validation))\n",
    "# print(len(y))\n",
    "\n",
    "# # Now let's get the X with the same indexes. \n",
    "# print(X.shape)\n",
    "# X_validation = X[1:3,:,:]\n",
    "# print(X.shape)\n",
    "# print(X_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "4548/4548 [==============================] - 23s 5ms/step - loss: 0.9563 - acc: 0.6838\n",
      "Epoch 2/4\n",
      "4548/4548 [==============================] - 18s 4ms/step - loss: 0.8399 - acc: 0.6953\n",
      "Epoch 3/4\n",
      "4548/4548 [==============================] - 19s 4ms/step - loss: 0.8259 - acc: 0.6953\n",
      "Epoch 4/4\n",
      "4548/4548 [==============================] - 19s 4ms/step - loss: 0.8263 - acc: 0.6953\n",
      "506/506 [==============================] - 6s 12ms/step\n",
      "acc: 79.05%\n",
      "Epoch 1/4\n",
      "4548/4548 [==============================] - 24s 5ms/step - loss: 0.9322 - acc: 0.6783\n",
      "Epoch 2/4\n",
      "4548/4548 [==============================] - 19s 4ms/step - loss: 0.8382 - acc: 0.6873\n",
      "Epoch 3/4\n",
      "4548/4548 [==============================] - 20s 4ms/step - loss: 0.8380 - acc: 0.6873\n",
      "Epoch 4/4\n",
      "4548/4548 [==============================] - 18s 4ms/step - loss: 0.8384 - acc: 0.6873\n",
      "506/506 [==============================] - 6s 12ms/step\n",
      "acc: 86.17%\n",
      "Epoch 1/4\n",
      "4548/4548 [==============================] - 24s 5ms/step - loss: 0.9295 - acc: 0.6755\n",
      "Epoch 2/4\n",
      "4548/4548 [==============================] - 19s 4ms/step - loss: 0.8422 - acc: 0.6847\n",
      "Epoch 3/4\n",
      "4548/4548 [==============================] - 19s 4ms/step - loss: 0.8417 - acc: 0.6847\n",
      "Epoch 4/4\n",
      "4548/4548 [==============================] - 19s 4ms/step - loss: 0.8422 - acc: 0.6847\n",
      "506/506 [==============================] - 6s 12ms/step\n",
      "acc: 88.54%\n",
      "Epoch 1/4\n",
      "4548/4548 [==============================] - 25s 6ms/step - loss: 0.9420 - acc: 0.6847\n",
      "Epoch 2/4\n",
      "4548/4548 [==============================] - 19s 4ms/step - loss: 0.8191 - acc: 0.6996\n",
      "Epoch 3/4\n",
      "4548/4548 [==============================] - 18s 4ms/step - loss: 0.7680 - acc: 0.7047\n",
      "Epoch 4/4\n",
      "4548/4548 [==============================] - 18s 4ms/step - loss: 0.7427 - acc: 0.7142\n",
      "506/506 [==============================] - 6s 13ms/step\n",
      "acc: 78.06%\n",
      "Epoch 1/4\n",
      "4549/4549 [==============================] - 26s 6ms/step - loss: 0.9154 - acc: 0.6909\n",
      "Epoch 2/4\n",
      "4549/4549 [==============================] - 19s 4ms/step - loss: 0.8200 - acc: 0.6993\n",
      "Epoch 3/4\n",
      "4549/4549 [==============================] - 19s 4ms/step - loss: 0.8202 - acc: 0.6993\n",
      "Epoch 4/4\n",
      "4549/4549 [==============================] - 18s 4ms/step - loss: 0.8200 - acc: 0.6993\n",
      "505/505 [==============================] - 6s 13ms/step\n",
      "acc: 75.45%\n",
      "Epoch 1/4\n",
      "4549/4549 [==============================] - 25s 6ms/step - loss: 0.9187 - acc: 0.7111\n",
      "Epoch 2/4\n",
      "4549/4549 [==============================] - 19s 4ms/step - loss: 0.7942 - acc: 0.7164\n",
      "Epoch 3/4\n",
      "4549/4549 [==============================] - 19s 4ms/step - loss: 0.7928 - acc: 0.7164\n",
      "Epoch 4/4\n",
      "4549/4549 [==============================] - 18s 4ms/step - loss: 0.7933 - acc: 0.7164\n",
      "505/505 [==============================] - 7s 14ms/step\n",
      "acc: 60.00%\n",
      "Epoch 1/4\n",
      "4549/4549 [==============================] - 28s 6ms/step - loss: 0.9665 - acc: 0.6766\n",
      "Epoch 2/4\n",
      "4549/4549 [==============================] - 20s 4ms/step - loss: 0.8419 - acc: 0.6867\n",
      "Epoch 3/4\n",
      "4549/4549 [==============================] - 19s 4ms/step - loss: 0.8388 - acc: 0.6867\n",
      "Epoch 4/4\n",
      "4549/4549 [==============================] - 20s 4ms/step - loss: 0.8389 - acc: 0.6867\n",
      "505/505 [==============================] - 6s 13ms/step\n",
      "acc: 86.73%\n",
      "Epoch 1/4\n",
      "4549/4549 [==============================] - 27s 6ms/step - loss: 0.9711 - acc: 0.6883\n",
      "Epoch 2/4\n",
      "4549/4549 [==============================] - 19s 4ms/step - loss: 0.8346 - acc: 0.6984\n",
      "Epoch 3/4\n",
      "4549/4549 [==============================] - 19s 4ms/step - loss: 0.8213 - acc: 0.6984\n",
      "Epoch 4/4\n",
      "4549/4549 [==============================] - 18s 4ms/step - loss: 0.8211 - acc: 0.6984\n",
      "505/505 [==============================] - 6s 12ms/step\n",
      "acc: 76.24%\n",
      "Epoch 1/4\n",
      "4549/4549 [==============================] - 28s 6ms/step - loss: 0.9665 - acc: 0.7239\n",
      "Epoch 2/4\n",
      "4549/4549 [==============================] - 19s 4ms/step - loss: 0.7763 - acc: 0.7380\n",
      "Epoch 3/4\n",
      "4549/4549 [==============================] - 19s 4ms/step - loss: 0.7561 - acc: 0.7380\n",
      "Epoch 4/4\n",
      "4549/4549 [==============================] - 19s 4ms/step - loss: 0.7561 - acc: 0.7380\n",
      "505/505 [==============================] - 7s 14ms/step\n",
      "acc: 40.59%\n",
      "Epoch 1/4\n",
      "4549/4549 [==============================] - 29s 6ms/step - loss: 0.8737 - acc: 0.7327\n",
      "Epoch 2/4\n",
      "4549/4549 [==============================] - 19s 4ms/step - loss: 0.7444 - acc: 0.7454\n",
      "Epoch 3/4\n",
      "4549/4549 [==============================] - 19s 4ms/step - loss: 0.7440 - acc: 0.7454\n",
      "Epoch 4/4\n",
      "4549/4549 [==============================] - 20s 4ms/step - loss: 0.7441 - acc: 0.7454\n",
      "505/505 [==============================] - 6s 13ms/step\n",
      "acc: 33.86%\n",
      "70.47% (+/- 18.35%)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "seed = 42\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "    # create model\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=70, return_sequences= True, input_shape=(lookback,25)))\n",
    "    model.add(LSTM(units=40, return_sequences=True))\n",
    "    model.add(LSTM(units=30, return_sequences=True))\n",
    "    model.add(LSTM(units=10))\n",
    "    model.add(Dense(units=3, activation='sigmoid'))\n",
    "    \n",
    "    y_b_train = Y[train]\n",
    "    y_b_test = Y[test]\n",
    "    \n",
    "    X_train = X[train]\n",
    "    X_test = X[test]\n",
    "    \n",
    "    \n",
    "    y_train_binary = to_categorical(y_b_train)\n",
    "    y_test_binary = to_categorical(y_b_test)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    model.fit(X_train, y_train_binary, epochs=4, batch_size=128)\n",
    "\n",
    "    scores = model.evaluate(X_test,y_test_binary, verbose=1)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 506,  507,  508, ..., 5051, 5052, 5053])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.9030515e-04 9.8091495e-01 1.0628104e-03]\n",
      "[[   0    0    0]\n",
      " [5049    0    0]\n",
      " [   5    0    0]]\n",
      "hold\n",
      "[0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "# print(Y_pred[0])\n",
    "\n",
    "# test = [[round(x[0]), round(x[1]), round(x[2])] for x in Y_pred]\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# def get_confusion_matrix(Y, Y_pred):\n",
    "    \n",
    "#     y = []\n",
    "#     y_pred = []\n",
    "    \n",
    "#     for i in range(Y.shape[0]):\n",
    "#         if Y[i][0] >0:\n",
    "#             y.append('buy')\n",
    "        \n",
    "#         elif Y[i][1] >0:\n",
    "#             y.append('hold')\n",
    "        \n",
    "#         else:\n",
    "#             y.append('sell')\n",
    "            \n",
    "    \n",
    "#     for i in range(Y_pred.shape[0]):\n",
    "#         if Y_pred[i][0] >0:\n",
    "#             y_pred.append('buy')\n",
    "        \n",
    "#         elif Y_pred[i][1] >0:\n",
    "#             y_pred.append('hold')\n",
    "        \n",
    "#         else:\n",
    "#             y_pred.append('sell')\n",
    "        \n",
    "    \n",
    "#     return y, y_pred\n",
    "\n",
    "# Y, y_pred = get_confusion_matrix(y_binary,Y_pred)\n",
    "\n",
    "\n",
    "# print(confusion_matrix(Y, y_pred))\n",
    "# print(temp[0])\n",
    "# print(y_binary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = X.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalData_0</th>\n",
       "      <th>OriginalData_1</th>\n",
       "      <th>Volume_0</th>\n",
       "      <th>Volume_1</th>\n",
       "      <th>Volume_2</th>\n",
       "      <th>Volume_3</th>\n",
       "      <th>Volume_4</th>\n",
       "      <th>Volume_5</th>\n",
       "      <th>Volatility_0</th>\n",
       "      <th>Volatility_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Trend_2</th>\n",
       "      <th>Trend_3</th>\n",
       "      <th>Trend_4</th>\n",
       "      <th>Trend_5</th>\n",
       "      <th>Trend_6</th>\n",
       "      <th>Momentum_0</th>\n",
       "      <th>Momentum_1</th>\n",
       "      <th>Momentum_2</th>\n",
       "      <th>Others_0</th>\n",
       "      <th>Others_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.039052</td>\n",
       "      <td>-0.007701</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>-0.008013</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>-0.013782</td>\n",
       "      <td>0.046802</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001135</td>\n",
       "      <td>-0.010623</td>\n",
       "      <td>0.042895</td>\n",
       "      <td>-0.042629</td>\n",
       "      <td>0.062107</td>\n",
       "      <td>0.041504</td>\n",
       "      <td>0.048005</td>\n",
       "      <td>-0.027294</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>-0.000360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.042133</td>\n",
       "      <td>-0.008209</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.019749</td>\n",
       "      <td>-0.022744</td>\n",
       "      <td>-0.001013</td>\n",
       "      <td>-0.001172</td>\n",
       "      <td>-0.013445</td>\n",
       "      <td>0.036927</td>\n",
       "      <td>0.073391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017024</td>\n",
       "      <td>-0.032375</td>\n",
       "      <td>0.032682</td>\n",
       "      <td>-0.013867</td>\n",
       "      <td>0.029739</td>\n",
       "      <td>0.053535</td>\n",
       "      <td>0.030563</td>\n",
       "      <td>-0.019515</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>-0.000596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.042705</td>\n",
       "      <td>-0.008313</td>\n",
       "      <td>-0.001122</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>-0.003901</td>\n",
       "      <td>-0.004907</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>-0.010391</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013694</td>\n",
       "      <td>-0.033869</td>\n",
       "      <td>0.028497</td>\n",
       "      <td>-0.007240</td>\n",
       "      <td>0.025442</td>\n",
       "      <td>0.055001</td>\n",
       "      <td>0.027472</td>\n",
       "      <td>-0.013972</td>\n",
       "      <td>0.006341</td>\n",
       "      <td>-0.000876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.042193</td>\n",
       "      <td>-0.008221</td>\n",
       "      <td>-0.005459</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>-0.006957</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>-0.007910</td>\n",
       "      <td>0.050761</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008040</td>\n",
       "      <td>-0.039490</td>\n",
       "      <td>0.024184</td>\n",
       "      <td>-0.000716</td>\n",
       "      <td>0.024071</td>\n",
       "      <td>0.053673</td>\n",
       "      <td>0.027048</td>\n",
       "      <td>-0.013310</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>0.000612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.042252</td>\n",
       "      <td>-0.008236</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>-0.005756</td>\n",
       "      <td>0.011697</td>\n",
       "      <td>-0.005217</td>\n",
       "      <td>0.050659</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>-0.037750</td>\n",
       "      <td>0.019704</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.015005</td>\n",
       "      <td>0.051826</td>\n",
       "      <td>0.027958</td>\n",
       "      <td>-0.011900</td>\n",
       "      <td>-0.003226</td>\n",
       "      <td>0.001157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    OriginalData_0  OriginalData_1  Volume_0  Volume_1  Volume_2  Volume_3  \\\n",
       "26        0.039052       -0.007701  0.008007  0.002738 -0.008013  0.000283   \n",
       "38        0.042133       -0.008209  0.005843  0.019749 -0.022744 -0.001013   \n",
       "42        0.042705       -0.008313 -0.001122  0.006269 -0.003901 -0.004907   \n",
       "44        0.042193       -0.008221 -0.005459  0.005599  0.000247 -0.006957   \n",
       "45        0.042252       -0.008236 -0.000062  0.002961  0.002409 -0.005756   \n",
       "\n",
       "    Volume_4  Volume_5  Volatility_0  Volatility_1  ...   Trend_2   Trend_3  \\\n",
       "26  0.005950 -0.013782      0.046802      0.007247  ... -0.001135 -0.010623   \n",
       "38 -0.001172 -0.013445      0.036927      0.073391  ...  0.017024 -0.032375   \n",
       "42  0.004775 -0.010391      0.050601      0.007871  ...  0.013694 -0.033869   \n",
       "44  0.006305 -0.007910      0.050761      0.007799  ...  0.008040 -0.039490   \n",
       "45  0.011697 -0.005217      0.050659      0.007706  ...  0.011961 -0.037750   \n",
       "\n",
       "     Trend_4   Trend_5   Trend_6  Momentum_0  Momentum_1  Momentum_2  \\\n",
       "26  0.042895 -0.042629  0.062107    0.041504    0.048005   -0.027294   \n",
       "38  0.032682 -0.013867  0.029739    0.053535    0.030563   -0.019515   \n",
       "42  0.028497 -0.007240  0.025442    0.055001    0.027472   -0.013972   \n",
       "44  0.024184 -0.000716  0.024071    0.053673    0.027048   -0.013310   \n",
       "45  0.019704  0.001172  0.015005    0.051826    0.027958   -0.011900   \n",
       "\n",
       "    Others_0  Others_1  \n",
       "26  0.003648 -0.000360  \n",
       "38  0.005015 -0.000596  \n",
       "42  0.006341 -0.000876  \n",
       "44 -0.000676  0.000612  \n",
       "45 -0.003226  0.001157  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp.loc[test].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
